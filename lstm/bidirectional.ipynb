{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Sentence #           Word  POS Tag\n",
      "0        Sentence: 1      Thousands  NNS   O\n",
      "1                NaN             of   IN   O\n",
      "2                NaN  demonstrators  NNS   O\n",
      "3                NaN           have  VBP   O\n",
      "4                NaN        marched  VBN   O\n",
      "...              ...            ...  ...  ..\n",
      "1048570          NaN           they  PRP   O\n",
      "1048571          NaN      responded  VBD   O\n",
      "1048572          NaN             to   TO   O\n",
      "1048573          NaN            the   DT   O\n",
      "1048574          NaN         attack   NN   O\n",
      "\n",
      "[1048575 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "data = pd.read_csv(\"ner_annotated.csv\", encoding='unicode_escape')\n",
    "\n",
    "print(data)\n",
    "\n",
    "\n",
    "def get_dict_map(data, token_or_tag):\n",
    "    tok2idx = {}\n",
    "    idx2tok = {}\n",
    "\n",
    "    if token_or_tag == 'token':\n",
    "        vocab = list(set(data['Word'].to_list()))\n",
    "    else:\n",
    "        vocab = list(set(data['Tag'].to_list()))\n",
    "\n",
    "    idx2tok = {idx: tok for idx, tok in enumerate(vocab)}\n",
    "    tok2idx = {tok: idx for idx, tok in enumerate(vocab)}\n",
    "    return tok2idx, idx2tok\n",
    "\n",
    "\n",
    "token2idx, idx2token = get_dict_map(data, 'token')\n",
    "tag2idx, idx2tag = get_dict_map(data, 'tag')\n",
    "\n",
    "data['Word_idx'] = data['Word'].map(token2idx)\n",
    "data['Tag_idx'] = data['Tag'].map(tag2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #     True\n",
       "Word          False\n",
       "POS           False\n",
       "Tag           False\n",
       "Word_idx      False\n",
       "Tag_idx       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064969/1193743703.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  data_group = data_fillna.groupby(['Sentence #'], as_index=False)[\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
       "      <td>[25182, 5165, 13638, 14991, 12006, 7041, 33589...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 6, 10, 10, 10, 10, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
       "      <td>[JJ, NNS, VBP, PRP, VBP, TO, VB, NN, TO, JJ, J...</td>\n",
       "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[6562, 6172, 31128, 17865, 24565, 31781, 18891...</td>\n",
       "      <td>[14, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
       "      <td>[NN, NNS, NNP, VBD, JJ, NNS, IN, DT, NNP, JJ, ...</td>\n",
       "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...</td>\n",
       "      <td>[34647, 27090, 32665, 4664, 13529, 25278, 3216...</td>\n",
       "      <td>[10, 10, 16, 10, 10, 10, 10, 10, 6, 10, 10, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[They, left, after, a, tense, hour-long, stand...</td>\n",
       "      <td>[PRP, VBD, IN, DT, NN, JJ, NN, IN, NN, NNS, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[23307, 23487, 15211, 30266, 5702, 11497, 2886...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[U.N., relief, coordinator, Jan, Egeland, said...</td>\n",
       "      <td>[NNP, NN, NN, NNP, NNP, VBD, NNP, ,, NNP, ,, J...</td>\n",
       "      <td>[B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...</td>\n",
       "      <td>[2602, 2926, 3763, 16853, 7119, 29535, 4179, 2...</td>\n",
       "      <td>[6, 10, 10, 13, 0, 10, 16, 10, 6, 10, 14, 10, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #                                               Word  \\\n",
       "0      Sentence: 1  [Thousands, of, demonstrators, have, marched, ...   \n",
       "1     Sentence: 10  [Iranian, officials, say, they, expect, to, ge...   \n",
       "2    Sentence: 100  [Helicopter, gunships, Saturday, pounded, mili...   \n",
       "3   Sentence: 1000  [They, left, after, a, tense, hour-long, stand...   \n",
       "4  Sentence: 10000  [U.N., relief, coordinator, Jan, Egeland, said...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  [NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...   \n",
       "1  [JJ, NNS, VBP, PRP, VBP, TO, VB, NN, TO, JJ, J...   \n",
       "2  [NN, NNS, NNP, VBD, JJ, NNS, IN, DT, NNP, JJ, ...   \n",
       "3     [PRP, VBD, IN, DT, NN, JJ, NN, IN, NN, NNS, .]   \n",
       "4  [NNP, NN, NN, NNP, NNP, VBD, NNP, ,, NNP, ,, J...   \n",
       "\n",
       "                                                 Tag  \\\n",
       "0  [O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...   \n",
       "1  [B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
       "2  [O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...   \n",
       "3                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4  [B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...   \n",
       "\n",
       "                                            Word_idx  \\\n",
       "0  [25182, 5165, 13638, 14991, 12006, 7041, 33589...   \n",
       "1  [6562, 6172, 31128, 17865, 24565, 31781, 18891...   \n",
       "2  [34647, 27090, 32665, 4664, 13529, 25278, 3216...   \n",
       "3  [23307, 23487, 15211, 30266, 5702, 11497, 2886...   \n",
       "4  [2602, 2926, 3763, 16853, 7119, 29535, 4179, 2...   \n",
       "\n",
       "                                             Tag_idx  \n",
       "0  [10, 10, 10, 10, 10, 10, 6, 10, 10, 10, 10, 10...  \n",
       "1  [14, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...  \n",
       "2  [10, 10, 16, 10, 10, 10, 10, 10, 6, 10, 10, 10...  \n",
       "3       [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]  \n",
       "4  [6, 10, 10, 13, 0, 10, 16, 10, 6, 10, 14, 10, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fillna = data.fillna(method='ffill', axis=0)\n",
    "data_group = data_fillna.groupby(['Sentence #'], as_index=False)[\n",
    "    'Word', 'POS', 'Tag', 'Word_idx', 'Tag_idx'].agg(lambda x: list(x))\n",
    "data_group.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee1cd9b302554fc418f8b84f658dab3188467b37dcaeb92c53502d81e2e402a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
