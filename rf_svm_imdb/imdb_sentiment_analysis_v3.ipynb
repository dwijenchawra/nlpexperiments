{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Analysis - XGBoost & SVM\n",
    "\n",
    "In this lab, we will be revisiting the IMDB Movie Review Dataset for a more in-depth analysis and to test more complicated models. This dataset consists of 50K movie reviews that are labeled as positive or negative based on their sentiment toward a film. This week, we will focus on using SVM and XGBoost for the classification task. Similar to the first iteration with this task, this notebook will guide you through 4 main steps:\n",
    "\n",
    "1. Text Preprocessing\n",
    "2. Feature Engineering\n",
    "3. Model Fitting\n",
    "4. Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, matthews_corrcoef\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import chi2_contingency\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text Preprocessing\n",
    "\n",
    "The first step to this process will be loading the data. The data can be found [here](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?resource=download). Please download the data from this page which will produce a zip folder. Upon unzipping the folder, a file entitled \"IMDB Dataset.csv\" will be produced. Create a folder to hold data used in this course and place the \"IMDB Dataset.csv\" file in it. Next make sure that every package in the imports below is installed. The \"nltk.download()\" lines only need to be ran once. So comment them out with a # at the beginning of the line after the downloads have been completed.\n",
    "\n",
    "In the following cell, set the **data_path** variable equal to the path of the \"IMDB Dataset.csv\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\GAUTHIER\\Documents\\Projects\\DataMine\\Data\\IMDB_Dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization and Cleaning\n",
    "\n",
    "In the next two cells, the data will be loaded, cleaned, and normalized. This will include:\n",
    "\n",
    "1. Removing HTML chunks\n",
    "2. Transforming text to lower case\n",
    "3. Tokenizing text\n",
    "4. Removing Stop Words and punctuation\n",
    "5. Lemmatizing Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "data.columns = ['text', 'label']\n",
    "data['label'] = data.label.map({'negative': 0, 'positive': 1})\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punct_remover = str.maketrans('', '', punctuation)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub('<.*?>', '', text)\n",
    "    tokens = wordpunct_tokenize(text.lower())\n",
    "    tokens = [i.translate(punct_remover) for i in tokens]\n",
    "    tokens = [i for i in tokens if i not in stop_words]\n",
    "    tokens = [wnl.lemmatize(i) for i in tokens]\n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:25<00:00, 1935.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Tokens per Review: 120\n"
     ]
    }
   ],
   "source": [
    "text_data = []\n",
    "for i in tqdm(data.text):\n",
    "    text_data.append(preprocess_text(i))\n",
    "data['text'] = text_data\n",
    "\n",
    "avg_tokens = sum([len(i.split()) for i in data.text]) / len(data.text)\n",
    "print(f\"Average Number of Tokens per Review: {round(avg_tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "In this step, we will work through generating a vector representation of each review in the corpus. There are two feature representations that we will be testing during this step: Bag-of-Words and TFIDF. For each review, the Bag-of-Words representation will generate a vector that is the size of the corpus vocabulary, where each element in the vector will correspond to the number of occurrences of a specific token in the review. To generate these representations, we will be using the CountVectorizer object from scikit-learn; the documentation can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html?highlight=countvectorizer#sklearn.feature_extraction.text.CountVectorizer). On the other hand, the TFIDF method will also yield a vector equal to the size of the corpus vocabulary, but, instead of token counts, each element will correspond to the Term Frequency Inverse Document Frequency (TFIDF) of the specific token. This value is equal to the frequency of the term in the document multiplied by the inverse of how often the term occurs in all documents. The exact formula can be shown below:\n",
    "\n",
    "$TDIDF(t, d) = TF(t, d) * \\log{[\\frac{n}{(DF(t) + 1)}]}$\n",
    "\n",
    "In short, this metric gives a higher score for terms that are frequent in a document and then down scores terms that are common across all documents. To create this feature representation, we will be using the TfidfVectorizer object from scikit-learn; documentation can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer). Similar to last week, there are a few variables that can be tuned here, using either Bag-of-Words or TFIDF:\n",
    "\n",
    "* ngram_min - Minimum size of ngrams to use. Acceptable values are integers greater than or equal to 1\n",
    "* ngram_max - Maximum size of ngrams to use. Acceptable values are integers greater than or equal to 1\n",
    "* min_df - Minimum document frequency to be included in model. Acceptable values are integers greater than or equal to 1 to denote the raw count or float values in [0.0, 1.0] to denote percent frequency\n",
    "* max_df - Minimum document frequency to be included in model. Same acceptable values as min_df\n",
    "\n",
    "**Experiment:** Try different ngram ranges and frequency thresholds (min and max) for both the Bag-of-Words and TfIdf methods. Observe and note the changes in test performance, and model training time, as these parameters are changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "To limit the complexity of the model, it may be good to only inlcude the terms that have the strongest relationship with the label. For this, we will look at how correlated each token is with the target variable. We can create two binary features: whether a token is present in a document and the document sentiment label. Matthews Correlation Coefficient can be used with these two features to determine how correlated the feature is with the label. The **get_correlated_features** function can be used to set a specific number of features which corresponds to the N most correlated features; the attribute in the function is called **num_features**. Be aware that the process of finding correlated features can be time consuming. Also, I **highly recommend using TFIDF features only**, as this method seems to converge better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlated_matrix(text_data, labels, min_df=50, p_value=0.05, num_features=1000):\n",
    "    # Get Document Term Matrix\n",
    "    count_vector = CountVectorizer(ngram_range=(1, 1), min_df=50)\n",
    "    ngram_counts = count_vector.fit_transform(text_data)\n",
    "    doc_tokens = count_vector.inverse_transform(ngram_counts)\n",
    "\n",
    "    # Map tokens to ids\n",
    "    id2token = {i: j for i, j in enumerate(count_vector.get_feature_names())}\n",
    "    token2id = {j: i for i, j in id2token.items()}\n",
    "    doc_tokens = [set(token2id[j] for j in i) for i in doc_tokens]\n",
    "\n",
    "    # Get the label for each token occurrence\n",
    "    token_labels = []\n",
    "    doc_id = 0\n",
    "    for doc, label in zip(doc_tokens, labels):\n",
    "        token_labels.extend([(i, label, doc_id) for i in doc])\n",
    "        doc_id += 1\n",
    "    token_labels = pd.DataFrame(token_labels)\n",
    "    token_labels.columns = [\"Token\", \"Label\", \"Document\"]\n",
    "    token_labels['Token_Present'] = 1\n",
    "    doc_labels = {row.Document: row.Label for row in token_labels.itertuples()}\n",
    "\n",
    "    # Calculate correlation to label for each token\n",
    "    all_docs = token_labels.Document.unique()\n",
    "    token2corr = Counter()\n",
    "    for token_id in tqdm(id2token.keys()):\n",
    "        all_token_docs = (\n",
    "            pd.DataFrame({\"Document\": all_docs})\n",
    "            .assign(Token=token_id)\n",
    "            )\n",
    "        token_id_labels = (\n",
    "            token_labels[token_labels.Token == token_id]\n",
    "            .merge(all_token_docs, on=['Token', 'Document'], how='outer')\n",
    "            .assign(\n",
    "                Token_Present = lambda df: df.Token_Present.fillna(0),\n",
    "                Label = lambda df: df.Document.map(doc_labels))\n",
    "            )\n",
    "        # cont_table = token_id_labels.groupby([\"Token_Present\", \"Label\"]).size().unstack(fill_value=0).values\n",
    "        # chi2, p, dof, ex = chi2_contingency(cont_table)\n",
    "        # token2corr[token_id] = p\n",
    "        token2corr[token_id] = matthews_corrcoef(token_id_labels.Label, token_id_labels.Token_Present)\n",
    "    \n",
    "    # Return Document-Term Matrix of correlated features\n",
    "    # correlated_features = {k: v for k, v in token2corr.items() if v < 0.05}\n",
    "    # correlated_tokens = sorted(correlated_features.keys())\n",
    "    correlated_features = sorted(token2corr.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "    print('Most Correlated Features')\n",
    "    print('-' * 25)\n",
    "    for i, j in correlated_features[:10]:\n",
    "        print(id2token[i], j)\n",
    "    correlated_tokens = [k for k, v in correlated_features[:num_features]]\n",
    "    correlated_data = ngram_counts.T[correlated_tokens].T\n",
    "\n",
    "    return correlated_data, count_vector, correlated_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(data, test_size=0.2, feature_type='bow', ngram_min=1, ngram_max=1, min_df=1, max_df=1.0):\n",
    "    \"\"\"\n",
    "    Function to generate features for train and test data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data - Dataframe with columns 'text' and 'label'\n",
    "    test_size - Proportion of data that will be held out for evaluation\n",
    "    feature_type - Type of features to use as represenation. Options are 'bow' or 'tfidf'\n",
    "    max_df - When building the vocabulary ignore terms that have a document frequency strictly\n",
    "             higher than the given threshold (corpus-specific stop words). If float, the parameter\n",
    "             represents a proportion of documents, integer absolute counts. This parameter is ignored\n",
    "             if vocabulary is not None.\n",
    "    min_df - When building the vocabulary ignore terms that have a document frequency strictly lower than\n",
    "            the given threshold. If float, the parameter represents a proportion of documents, integer\n",
    "            absolute counts. This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_train - Input features for the train set\n",
    "    y_train - Labels for the train set\n",
    "    x_test - Input features for the test set\n",
    "    y_test - Labels for the test set\n",
    "    \"\"\"\n",
    "\n",
    "    # Split data into Train and Test\n",
    "    train_df, test_df = train_test_split(data, test_size=0.2)\n",
    "\n",
    "    # Instantiate Object to generate feature representations\n",
    "    if feature_type == 'bow':\n",
    "        vectorizer = CountVectorizer(ngram_range=(ngram_min, ngram_max), min_df=min_df, max_df=max_df)\n",
    "    elif feature_type == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(ngram_min, ngram_max), min_df=min_df, max_df=max_df)\n",
    "    else:\n",
    "        raise ValueError(\"feature_type must be set to either 'bow' or 'tfidf'.\")\n",
    "    \n",
    "    # Generate features for train and test set\n",
    "    x_train = vectorizer.fit_transform(train_df.text)\n",
    "    x_test = vectorizer.transform(test_df.text)\n",
    "    y_train = train_df.label.values\n",
    "    y_test = test_df.label.values\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_correlated_features(data, test_size=0.2, num_features=1000, feature_type='bow', ngram_min=1, ngram_max=1, min_df=1, max_df=1.0):\n",
    "    \"\"\"\n",
    "    Function to generate features for train and test data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data - Dataframe with columns 'text' and 'label'\n",
    "    test_size - Proportion of data that will be held out for evaluation\n",
    "    num_features - Number of features to include which will be the top N most correlated features\n",
    "    feature_type - Type of features to use as represenation. Options are 'bow' or 'tfidf'\n",
    "    max_df - When building the vocabulary ignore terms that have a document frequency strictly\n",
    "             higher than the given threshold (corpus-specific stop words). If float, the parameter\n",
    "             represents a proportion of documents, integer absolute counts. This parameter is ignored\n",
    "             if vocabulary is not None.\n",
    "    min_df - When building the vocabulary ignore terms that have a document frequency strictly lower than\n",
    "            the given threshold. If float, the parameter represents a proportion of documents, integer\n",
    "            absolute counts. This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_train - Input features for the train set\n",
    "    y_train - Labels for the train set\n",
    "    x_test - Input features for the test set\n",
    "    y_test - Labels for the test set\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check feature type for validity\n",
    "    if feature_type not in ['bow', 'tfidf']:\n",
    "        raise ValueError(\"feature_type must be set to either 'bow' or 'tfidf'.\")\n",
    "\n",
    "    # Split data into Train and Test\n",
    "    train_df, test_df = train_test_split(data, test_size=0.2)\n",
    "\n",
    "    # Get correlated features from the training set\n",
    "    x_train, count_vectorizer, correlated_tokens = get_correlated_matrix(\n",
    "        train_df.text.to_list(),\n",
    "        train_df.label.to_list(),\n",
    "        min_df=50\n",
    "        )\n",
    "    \n",
    "    # Generate features for train and test set\n",
    "    x_test = count_vectorizer.transform(test_df.text)\n",
    "    x_test = x_test.T[correlated_tokens].T\n",
    "    y_train = train_df.label.values\n",
    "    y_test = test_df.label.values\n",
    "\n",
    "    if feature_type == 'tfidf':\n",
    "        tfidf = TfidfTransformer()\n",
    "        x_train = tfidf.fit_transform(x_train)\n",
    "        x_test = tfidf.transform(x_test)\n",
    "    else:\n",
    "        scaler = StandardScaler(with_mean=False)\n",
    "        # scaler = MinMaxScaler()\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_type='tfidf'\n",
    "ngram_min=1\n",
    "ngram_max=2\n",
    "min_df=50\n",
    "max_df=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7877/7877 [05:30<00:00, 23.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Correlated Features\n",
      "-------------------------\n",
      "bad -0.2761095830942107\n",
      "worst -0.2541196374726938\n",
      "great 0.20152241046793526\n",
      "waste -0.1994667002886294\n",
      "awful -0.1988023129332317\n",
      "terrible -0.16940731605489462\n",
      "excellent 0.16927606444658036\n",
      "stupid -0.1575772528473143\n",
      "boring -0.15561216730852787\n",
      "wonderful 0.14970237474218126\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = generate_correlated_features(\n",
    "    data, num_features = 500, feature_type=feature_type, ngram_min=ngram_min, ngram_max=ngram_max, min_df=min_df, max_df=max_df\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Fitting\n",
    "\n",
    "In this section we will be working on fitting two different models for the Sentiment Analysis task: Support Vector Machine (SVM) and Random Forest. First, I will provide code to train the models, as well as produce evaluation metrics and a confusion matrix. Note that for the confusion matrix, we want to maximize the True Negative (top left) and True Positive (bottom right) for our models. Then, I will present a challenge for the groups to work through.\n",
    "\n",
    "### SVM\n",
    "\n",
    "The support vector machine is a commonly used model that creates a decision boundary between between data points of different classes. Below are a few videos to get a general idea of how Support Vector Machines work:\n",
    "\n",
    "1. Support Vector Machine in 2 minutes: [link](https://www.youtube.com/watch?v=_YPScrckx28)\n",
    "2. Support Vector Machines Part 1 (of 3) - Main Ideas: [link](https://www.youtube.com/watch?v=efR1C6CvhmE)\n",
    "\n",
    "To train this model, we will be using the SVC (Support Vector Classifier) object from scikit-learn; documentation can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics\n",
      "------------------\n",
      "Precision: 0.8697093817047006\n",
      "Recall: 0.8943040513437626\n",
      "F1: 0.8818352615445466\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1e00114d888>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model parameters and train model\n",
    "svm_classifier = LinearSVC(penalty='l2', C=10, tol=1e-5, max_iter=10000)\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Score Model\n",
    "svm_score = svm_classifier.score(x_test, y_test)\n",
    "test_pred = svm_classifier.predict(x_test)\n",
    "test_prec = precision_score(y_test, test_pred)\n",
    "test_recall = recall_score(y_test, test_pred)\n",
    "test_f1 = f1_score(y_test, test_pred)\n",
    "\n",
    "print(\"Evaluation Metrics\")\n",
    "print('-' * 18)\n",
    "print(f\"Precision: {test_prec}\")\n",
    "print(f\"Recall: {test_recall}\")\n",
    "print(f\"F1: {test_f1}\")\n",
    "print()\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_pred, normalize='true')\n",
    "ConfusionMatrixDisplay(conf_matrix, display_labels=[0, 1]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "The next model that we will be using is the Random Forest. This algorithm is based on decision trees. Before testing with this model, please watch the two videos below to gain an understanding of how this algorithm works.\n",
    "\n",
    "1. Decision Tree Classification Clearly Explained: [link](https://www.youtube.com/watch?v=ZVR2Way4nwQ)\n",
    "2. Random Forest Algorithm Clearly Explained: [link](https://www.youtube.com/watch?v=v6VJ2RO66Ag)\n",
    "\n",
    "To train this model, we will be using the RandomForestClassifier object from scikit-learn; documentation can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=random+forest#sklearn.ensemble.RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics\n",
      "------------------\n",
      "Precision: 0.8450816407805655\n",
      "Recall: 0.8511833132771761\n",
      "F1: 0.8481215027977619\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1e04ccf9108>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Score Model and Generate confusion matrix\n",
    "svm_score = rf_classifier.score(x_test, y_test)\n",
    "test_pred = rf_classifier.predict(x_test)\n",
    "test_prec = precision_score(y_test, test_pred)\n",
    "test_recall = recall_score(y_test, test_pred)\n",
    "test_f1 = f1_score(y_test, test_pred)\n",
    "print(\"Evaluation Metrics\")\n",
    "print('-' * 18)\n",
    "print(f\"Precision: {test_prec}\")\n",
    "print(f\"Recall: {test_recall}\")\n",
    "print(f\"F1: {test_f1}\")\n",
    "print()\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_pred, normalize='true')\n",
    "ConfusionMatrixDisplay(conf_matrix, display_labels=[0, 1]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Now, you have seen how to train and evaluate the models, and are familiar with how grid search works from the previous weeks assignment. Extra documentation for sklearn's GridSearch Algorithm can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV). This week, you will need to develop your own grid search algorithm that finds two things:\n",
    "\n",
    "1. Best feature type, number of features, ngram range, and minimum and maximum document frequencies. I suggest using the generate_features function that I have provided you. (note that ngram_min cannot be greater than ngram_max). Also get_correlated_features can be used for filtering based on correlation but this step can be slow. **ONLY USE TFIDF!!!**\n",
    "2. The best set of hyper-parameters for the model. Once again, the hyper-parameters that can be used for both models can be found in the models' documentation: [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=random+forest#sklearn.ensemble.RandomForestClassifier) and [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html?highlight=linearsvc#sklearn.svm.LinearSVC).\n",
    "3. **ONLY USE TFIDF!!!**. Bag-of-Words is not converging as well.\n",
    "\n",
    "The goal of this grid search is to maximize F1, so you will need to provide the set of hyper-parameters that generates the best F1 along with it's confusion matrix for each model. Good Luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b434a5580bac2dec3ed5ec53208c1d2c7faeaf78a39533c0db2f0c713da62bbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
